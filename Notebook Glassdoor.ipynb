{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FralSide/Portfolio/blob/Data-Cleaning/Notebook%20Glassdoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM5kd0m3Az_H"
      },
      "source": [
        "Project Data Cleaning - Data Science Job Posting on Glassdoor\n",
        "\n",
        "Source of the dataset: https://www.kaggle.com/datasets/rashikrahmanpritom/data-science-job-posting-on-glassdoor?select=Uncleaned_DS_jobs.csv\n",
        "\n",
        "The aim of the project is to use the Python language to clean up the data, enabling us to carry out a more detailed analysis in the future than if nothing had been done on the file.\n",
        "\n",
        "Integrated Development Environment: VS Code\n",
        "\n",
        "Few times in the notebook, I speak about future analysis but in this project the subject is only the data cleaning of the dataset.\n",
        "\n",
        "I choose to use english language on my project because it is often use in data department in companies and it allows me to improve my english."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWpzzRbmAz_I"
      },
      "source": [
        "Step 1: Importing required librairies for Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UvZSMYFtAz_I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #For data manipulation and analytics\n",
        "import numpy as np #For mathematical operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xklgrKGXAz_I"
      },
      "source": [
        "Step 2: Importing the csv file on VS Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LATk4ewAz_J"
      },
      "outputs": [],
      "source": [
        "URL = 'https://raw.githubusercontent.com/FralSide/Portfolio/refs/heads/Data-Cleaning/Uncleaned_DS_jobs.csv'\n",
        "\n",
        "Glassdoor_df = pd.read_csv(URL)\n",
        "\n",
        "#We are gonna look the 20th first lines of the datatset\n",
        "print(Glassdoor_df.head(20))\n",
        "\n",
        "#We want to know if each column as the right type of data\n",
        "print(Glassdoor_df.dtypes)\n",
        "\n",
        "#Later we will want the salaries to be integers to create new columns with it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Don't click on the execution button ! Google Colab is having trouble with this library, it's just to show the whole dataset in detail.\n",
        "\n",
        "from ydata_profiling import ProfileReport #To get a complete overview of the dataset\n",
        "\n",
        "#To get a complete overview of the dataset, do the following:\n",
        "Profile = ProfileReport(Glassdoor_df, title =\"Dataset summary\")\n",
        "Profile"
      ],
      "metadata": {
        "id": "ABdFATfZH7i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlK4-hnxAz_J"
      },
      "source": [
        "Step 3: Clear existing columns before creating new ones\n",
        "\n",
        "Here, we want to start with healthy columns so that we can create new ones later on for analysis.\n",
        "\n",
        "We can see that the column \"Salary Estimate\" is not accurate and doesn't allow us to use it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcZx-ippAz_J"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column \"Salary Estimate\"\n",
        "\n",
        "Glassdoor_df['Salary Estimate'] = Glassdoor_df['Salary Estimate'].str.split('(', n=1).str[0]\n",
        "Glassdoor_df['Salary Estimate'] = Glassdoor_df['Salary Estimate'].str.replace('$', '').str.strip()\n",
        "Glassdoor_df['Salary Estimate'] = Glassdoor_df['Salary Estimate'].str.replace('K', '').str.strip()\n",
        "\n",
        "\n",
        "print(Glassdoor_df.head(10))\n",
        "\n",
        "#We first split each line of 'Salary Estimate' with the delimiter '(' to delete the part'(Glassdoor est.)'\n",
        "#After we just removed the characters '$', 'K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwGsplcvAz_J"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column 'Company Name'\n",
        "#We can see that the rating and the company name is in the same cell while the rating is already in a column\n",
        "\n",
        "Glassdoor_df['Company Name'] = Glassdoor_df['Company Name'].str.split('\\n').str[0]\n",
        "\n",
        "print(Glassdoor_df.head(10))\n",
        "\n",
        "#We use the same method as for the column 'Salary Estimate' to delete the part of the line we don't want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S166dqp6Az_J"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column 'Size'\n",
        "#We prefer to see a range than to much characters\n",
        "\n",
        "Glassdoor_df['Size'] = Glassdoor_df['Size'].str.replace('to', '-').str.strip()\n",
        "Glassdoor_df['Size'] = Glassdoor_df['Size'].str.replace('employees', '').str.strip()\n",
        "\n",
        "print(Glassdoor_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtoN2FCjAz_J"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column 'Type of ownership'\n",
        "\n",
        "Glassdoor_df['Type of ownership'] = Glassdoor_df['Type of ownership'].str.replace('Company -', '').str.strip()\n",
        "\n",
        "\n",
        "print(Glassdoor_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jkvu3SrEAz_K"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column 'Revenue'\n",
        "\n",
        "Glassdoor_df['Revenue'] = Glassdoor_df['Revenue'].str.split('(', n=1).str[0]\n",
        "Glassdoor_df['Revenue'] = Glassdoor_df['Revenue'].str.replace('Unknown / Non-Applicable', 'NaN').str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlmpjNCvAz_K"
      },
      "outputs": [],
      "source": [
        "#Cleaning the column 'Competitors'\n",
        "#There is an occurrence of -1 but we prefer to see Nan instead\n",
        "\n",
        "Glassdoor_df['Competitors'] = Glassdoor_df['Competitors'].str.replace('-1', 'NaN').str.strip()\n",
        "\n",
        "print(Glassdoor_df.head(10))\n",
        "\n",
        "Glassdoor_df['Revenue'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuyWM7aRAz_K"
      },
      "source": [
        "Step 4: Creating new columns to develop insights later\n",
        "\n",
        "Since we have a clean dataset, we can now use it to add new columns for our analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qumUJjliAz_K"
      },
      "outputs": [],
      "source": [
        "#First, we will focus on the 'Salary Estimate' column\n",
        "\n",
        "#Splitting the column in 2 others as it is range salaries, we can create one for the minimum and one for the maximum\n",
        "Glassdoor_df[['Salary Min', 'Salary Max']] = Glassdoor_df['Salary Estimate'].str.split('-', expand=True)\n",
        "\n",
        "#Converting the column from string to integer to use mathematical operators\n",
        "Glassdoor_df['Salary Min'] = Glassdoor_df['Salary Min'].astype(int) * 1000\n",
        "Glassdoor_df['Salary Max'] = Glassdoor_df['Salary Max'].astype(int) * 1000\n",
        "\n",
        "#Use the 2 new columns to make an average salary by job\n",
        "Glassdoor_df['Average Salary'] = (Glassdoor_df['Salary Min'] + Glassdoor_df['Salary Max']) // 2\n",
        "\n",
        "print(Glassdoor_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asctoxhHAz_K"
      },
      "outputs": [],
      "source": [
        "#Now, on the column 'Location' we want to isolate the city and the state in 2 new columns.\n",
        "\n",
        "Glassdoor_df[['City', 'State']] = Glassdoor_df['Location'].str.split(',', n=1, expand=True)\n",
        "\n",
        "print(Glassdoor_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjV06qEsAz_K"
      },
      "outputs": [],
      "source": [
        "#Last, we want to know which skills are the most in demand on the data science market.\n",
        "\n",
        "#By looking in few Job Description, we can do a list of what we are looking for and put it in a function.\n",
        "#The function will work as a little ATS to extract the skills we want.\n",
        "\n",
        "def extract_skills(job_description):\n",
        "\n",
        "    skills = ['Python', 'R', 'SQL', 'Java', 'C++', 'Scala', 'Julia', 'AWS', 'Azure', 'Excel', 'Spark', 'Git', 'Tableau']\n",
        "    return [ x for x in skills if x.lower() in job_description.lower()]\n",
        "\n",
        "#With the function ready, we want to include all in a new column\n",
        "Glassdoor_df['Skills'] = Glassdoor_df['Job Description'].apply(extract_skills)\n",
        "\n",
        "print(Glassdoor_df.sample(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If we want to do analysis or vizualisations with an other technology as Power BI or Tableau, we need to put the dataframe in a new csv file in order to use it.\n",
        "Glassdoor_df.to_csv('Cleaned_Datajobs.csv', index=False)"
      ],
      "metadata": {
        "id": "ewO-_hobFqTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocDjPJkAz_K"
      },
      "source": [
        "The data cleaning is now finished.\n",
        "\n",
        "You were able to get an overview of my skills during this project.\n",
        "\n",
        "Thank you for taking the time to look at my project. I hope to have the opportunity to talk with you and prove my motivation to join your company."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}